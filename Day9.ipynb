{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xgS8UUaBWP4V",
        "outputId": "6f11e0e9-43fe-457b-f48c-43fc06b32b7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: Error 0.5014625866482507\n",
            "Epoch 100: Error 0.49983061361680425\n",
            "Epoch 200: Error 0.4980858377763339\n",
            "Epoch 300: Error 0.4957463818971118\n",
            "Epoch 400: Error 0.4925784959570654\n",
            "Epoch 500: Error 0.4883277845856713\n",
            "Epoch 600: Error 0.4827770971204906\n",
            "Epoch 700: Error 0.47580750463170896\n",
            "Epoch 800: Error 0.4673798500560846\n",
            "Epoch 900: Error 0.4575103184108751\n"
          ]
        }
      ],
      "source": [
        "#question 41\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "class NeuralNetwork:\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "\n",
        "        # Initialize weights and biases\n",
        "        self.weights_input_hidden = np.random.randn(self.input_size, self.hidden_size)\n",
        "        self.bias_input_hidden = np.random.randn(1, self.hidden_size)\n",
        "        self.weights_hidden_output = np.random.randn(self.hidden_size, self.output_size)\n",
        "        self.bias_hidden_output = np.random.randn(1, self.output_size)\n",
        "\n",
        "    def sigmoid(self, x):\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "\n",
        "    def sigmoid_derivative(self, x):\n",
        "        return x * (1 - x)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Forward propagation\n",
        "        self.hidden_layer_input = np.dot(x, self.weights_input_hidden) + self.bias_input_hidden\n",
        "        self.hidden_layer_output = self.sigmoid(self.hidden_layer_input)\n",
        "        self.output_layer_input = np.dot(self.hidden_layer_output, self.weights_hidden_output) + self.bias_hidden_output\n",
        "        self.output = self.sigmoid(self.output_layer_input)\n",
        "        return self.output\n",
        "\n",
        "    def backward(self, x, y, output, learning_rate):\n",
        "        # Backpropagation\n",
        "        self.error = y - output\n",
        "        self.output_delta = self.error * self.sigmoid_derivative(output)\n",
        "\n",
        "        self.hidden_error = self.output_delta.dot(self.weights_hidden_output.T)\n",
        "        self.hidden_delta = self.hidden_error * self.sigmoid_derivative(self.hidden_layer_output)\n",
        "\n",
        "        self.weights_hidden_output += self.hidden_layer_output.T.dot(self.output_delta) * learning_rate\n",
        "        self.bias_hidden_output += np.sum(self.output_delta) * learning_rate\n",
        "\n",
        "        self.weights_input_hidden += x.T.dot(self.hidden_delta) * learning_rate\n",
        "        self.bias_input_hidden += np.sum(self.hidden_delta) * learning_rate\n",
        "\n",
        "    def train(self, X, y, epochs, learning_rate):\n",
        "        for epoch in range(epochs):\n",
        "            output = self.forward(X)\n",
        "            self.backward(X, y, output, learning_rate)\n",
        "            if epoch % 100 == 0:\n",
        "                print(f'Epoch {epoch}: Error {np.mean(np.abs(self.error))}')\n",
        "\n",
        "# Example usage:\n",
        "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "y = np.array([[0], [1], [1], [0]])\n",
        "\n",
        "nn = NeuralNetwork(input_size=2, hidden_size=3, output_size=1)\n",
        "nn.train(X, y, epochs=1000, learning_rate=0.1)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#question 42\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import make_classification\n",
        "\n",
        "# Generate a random dataset and save it to a CSV file\n",
        "def generate_dataset(filename):\n",
        "    X, y = make_classification(n_samples=1000, n_features=5, n_classes=2, random_state=42)\n",
        "    df = pd.DataFrame(X, columns=[f\"feature_{i}\" for i in range(X.shape[1])])\n",
        "    df[\"target\"] = y\n",
        "    df.to_csv(filename, index=False)\n",
        "\n",
        "# Load the dataset from CSV file\n",
        "def load_dataset(filename):\n",
        "    df = pd.read_csv(filename)\n",
        "    X = df.iloc[:, :-1]  # Features\n",
        "    y = df.iloc[:, -1]   # Target variable\n",
        "    return X, y\n",
        "\n",
        "# Train the Naive Bayes classifier\n",
        "def train_naive_bayes(X_train, y_train):\n",
        "    model = GaussianNB()\n",
        "    model.fit(X_train, y_train)\n",
        "    return model\n",
        "\n",
        "# Test the Naive Bayes classifier\n",
        "def test_naive_bayes(model, X_test, y_test):\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    return accuracy\n",
        "\n",
        "# Main function\n",
        "def main():\n",
        "    # Generate a random dataset and save it to a CSV file\n",
        "    generate_dataset(\"training_data.csv\")\n",
        "\n",
        "    # Load the dataset\n",
        "    X, y = load_dataset(\"training_data.csv\")\n",
        "\n",
        "    # Split the dataset into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Train the Naive Bayes classifier\n",
        "    model = train_naive_bayes(X_train, y_train)\n",
        "\n",
        "    # Test the classifier\n",
        "    accuracy = test_naive_bayes(model, X_test, y_test)\n",
        "    print(\"Accuracy of Naive Bayes classifier:\", accuracy)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C03o96OWXQ7m",
        "outputId": "e782046d-a346-4728-fca2-7c1870e1c9fe"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of Naive Bayes classifier: 0.86\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#question 43\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train the kNN classifier\n",
        "k = 3  # Set the number of neighbors\n",
        "knn = KNeighborsClassifier(n_neighbors=k)\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = knn.predict(X_test)\n",
        "\n",
        "# Print correct and wrong predictions\n",
        "correct_predictions = 0\n",
        "wrong_predictions = 0\n",
        "for i in range(len(y_test)):\n",
        "    if y_pred[i] == y_test[i]:\n",
        "        print(f\"Correct prediction: Predicted class {y_pred[i]} for instance {X_test[i]}\")\n",
        "        correct_predictions += 1\n",
        "    else:\n",
        "        print(f\"Wrong prediction: Predicted class {y_pred[i]} but actual class is {y_test[i]} for instance {X_test[i]}\")\n",
        "        wrong_predictions += 1\n",
        "\n",
        "# Compute accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"\\nAccuracy:\", accuracy)\n",
        "print(\"Number of correct predictions:\", correct_predictions)\n",
        "print(\"Number of wrong predictions:\", wrong_predictions)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2rnghaOGXtmu",
        "outputId": "52c5d504-72cb-4bfb-ea50-e6beb9925c73"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correct prediction: Predicted class 1 for instance [6.1 2.8 4.7 1.2]\n",
            "Correct prediction: Predicted class 0 for instance [5.7 3.8 1.7 0.3]\n",
            "Correct prediction: Predicted class 2 for instance [7.7 2.6 6.9 2.3]\n",
            "Correct prediction: Predicted class 1 for instance [6.  2.9 4.5 1.5]\n",
            "Correct prediction: Predicted class 1 for instance [6.8 2.8 4.8 1.4]\n",
            "Correct prediction: Predicted class 0 for instance [5.4 3.4 1.5 0.4]\n",
            "Correct prediction: Predicted class 1 for instance [5.6 2.9 3.6 1.3]\n",
            "Correct prediction: Predicted class 2 for instance [6.9 3.1 5.1 2.3]\n",
            "Correct prediction: Predicted class 1 for instance [6.2 2.2 4.5 1.5]\n",
            "Correct prediction: Predicted class 1 for instance [5.8 2.7 3.9 1.2]\n",
            "Correct prediction: Predicted class 2 for instance [6.5 3.2 5.1 2. ]\n",
            "Correct prediction: Predicted class 0 for instance [4.8 3.  1.4 0.1]\n",
            "Correct prediction: Predicted class 0 for instance [5.5 3.5 1.3 0.2]\n",
            "Correct prediction: Predicted class 0 for instance [4.9 3.1 1.5 0.1]\n",
            "Correct prediction: Predicted class 0 for instance [5.1 3.8 1.5 0.3]\n",
            "Correct prediction: Predicted class 1 for instance [6.3 3.3 4.7 1.6]\n",
            "Correct prediction: Predicted class 2 for instance [6.5 3.  5.8 2.2]\n",
            "Correct prediction: Predicted class 1 for instance [5.6 2.5 3.9 1.1]\n",
            "Correct prediction: Predicted class 1 for instance [5.7 2.8 4.5 1.3]\n",
            "Correct prediction: Predicted class 2 for instance [6.4 2.8 5.6 2.2]\n",
            "Correct prediction: Predicted class 0 for instance [4.7 3.2 1.6 0.2]\n",
            "Correct prediction: Predicted class 2 for instance [6.1 3.  4.9 1.8]\n",
            "Correct prediction: Predicted class 0 for instance [5.  3.4 1.6 0.4]\n",
            "Correct prediction: Predicted class 2 for instance [6.4 2.8 5.6 2.1]\n",
            "Correct prediction: Predicted class 2 for instance [7.9 3.8 6.4 2. ]\n",
            "Correct prediction: Predicted class 2 for instance [6.7 3.  5.2 2.3]\n",
            "Correct prediction: Predicted class 2 for instance [6.7 2.5 5.8 1.8]\n",
            "Correct prediction: Predicted class 2 for instance [6.8 3.2 5.9 2.3]\n",
            "Correct prediction: Predicted class 0 for instance [4.8 3.  1.4 0.3]\n",
            "Correct prediction: Predicted class 0 for instance [4.8 3.1 1.6 0.2]\n",
            "\n",
            "Accuracy: 1.0\n",
            "Number of correct predictions: 30\n",
            "Number of wrong predictions: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#question 44\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Sample English text data\n",
        "texts = [\n",
        "    \"I love machine learning\",\n",
        "    \"I hate rainy days\",\n",
        "    \"Machine learning is fascinating\",\n",
        "    \"I enjoy coding\",\n",
        "    \"Rainy days make me sad\",\n",
        "    \"Coding is fun\"\n",
        "]\n",
        "\n",
        "# Corresponding labels (0 for negative sentiment, 1 for positive sentiment)\n",
        "labels = [1, 0, 1, 1, 0, 1]\n",
        "\n",
        "# Splitting the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Vectorizing the text data\n",
        "vectorizer = CountVectorizer()\n",
        "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
        "X_test_vectorized = vectorizer.transform(X_test)\n",
        "\n",
        "# Training the Naive Bayes classifier\n",
        "classifier = MultinomialNB()\n",
        "classifier.fit(X_train_vectorized, y_train)\n",
        "\n",
        "# Making predictions\n",
        "predictions = classifier.predict(X_test_vectorized)\n",
        "\n",
        "# Calculating accuracy\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "print(\"Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0ZFZJadYEON",
        "outputId": "9db2decf-9ff6-4104-9e19-9b0e10a9a39b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pgmpy\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u1cpJhbLYmYc",
        "outputId": "0d519d00-fe64-4cb0-fcce-7c0434d1cbbf"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pgmpy\n",
            "  Downloading pgmpy-0.1.25-py3-none-any.whl (2.0 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.1/2.0 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m1.5/2.0 MB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from pgmpy) (3.2.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pgmpy) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from pgmpy) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from pgmpy) (1.2.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from pgmpy) (1.5.3)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from pgmpy) (3.1.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from pgmpy) (2.2.1+cu121)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.10/dist-packages (from pgmpy) (0.14.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from pgmpy) (4.66.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from pgmpy) (1.3.2)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from pgmpy) (3.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->pgmpy) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->pgmpy) (2023.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pgmpy) (3.3.0)\n",
            "Requirement already satisfied: patsy>=0.5.4 in /usr/local/lib/python3.10/dist-packages (from statsmodels->pgmpy) (0.5.6)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from statsmodels->pgmpy) (24.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->pgmpy) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->pgmpy) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->pgmpy) (1.12)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->pgmpy) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->pgmpy) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->pgmpy)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m57.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->pgmpy)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m59.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->pgmpy)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m81.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch->pgmpy)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch->pgmpy)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch->pgmpy)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch->pgmpy)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch->pgmpy)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch->pgmpy)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch->pgmpy)\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch->pgmpy)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->pgmpy) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->pgmpy)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m44.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5.4->statsmodels->pgmpy) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->pgmpy) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->pgmpy) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, pgmpy\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.99 nvidia-nvtx-cu12-12.1.105 pgmpy-0.1.25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#question 45\n",
        "\n",
        "# with no output, no needed. because this question has some errors, will update the fix real soon.\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pgmpy.models import BayesianNetwork\n",
        "from pgmpy.estimators import BayesianEstimator\n",
        "\n",
        "# Generate a random dataset\n",
        "np.random.seed(0)\n",
        "num_samples = 1000\n",
        "num_features = 14  # Assuming 14 features including the target variable\n",
        "\n",
        "data = {\n",
        "    \"age\": np.random.randint(20, 80, num_samples),\n",
        "    \"sex\": np.random.randint(0, 2, num_samples),\n",
        "    \"cp\": np.random.randint(0, 4, num_samples),\n",
        "    \"trestbps\": np.random.randint(90, 200, num_samples),\n",
        "    \"chol\": np.random.randint(100, 400, num_samples),\n",
        "    \"fbs\": np.random.randint(0, 2, num_samples),\n",
        "    \"restecg\": np.random.randint(0, 3, num_samples),\n",
        "    \"thalach\": np.random.randint(60, 220, num_samples),\n",
        "    \"exang\": np.random.randint(0, 2, num_samples),\n",
        "    \"oldpeak\": np.random.uniform(0, 6, num_samples),\n",
        "    \"slope\": np.random.randint(0, 3, num_samples),\n",
        "    \"ca\": np.random.randint(0, 5, num_samples),\n",
        "    \"thal\": np.random.randint(0, 4, num_samples),\n",
        "    \"heart_disease\": np.random.randint(0, 2, num_samples)  # Assuming binary classification (0: No, 1: Yes)\n",
        "}\n",
        "\n",
        "# Convert to DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Save the dataset to a CSV file\n",
        "df.to_csv(\"heart_disease_data.csv\", index=False)\n",
        "\n",
        "# Load a subset of the heart disease dataset\n",
        "chunk_size = 100  # Adjust the chunk size as needed\n",
        "chunks = pd.read_csv(\"heart_disease_data.csv\", chunksize=chunk_size)\n",
        "\n",
        "# Initialize an empty Bayesian network\n",
        "model = BayesianNetwork([])\n",
        "\n",
        "# Learn the parameters of the Bayesian network from data using BayesianEstimator in chunks\n",
        "for chunk in chunks:\n",
        "    model.fit(chunk, estimator=BayesianEstimator, prior_type='BDeu', equivalent_sample_size=1000, state_names=chunk.columns)\n",
        "\n",
        "# Diagnosis: Set evidence for patient features\n",
        "evidence = {\n",
        "    \"age\": [63],\n",
        "    \"sex\": [1],  # 1 for male, 0 for female\n",
        "    \"cp\": [3],\n",
        "    \"trestbps\": [145],\n",
        "    \"chol\": [233],\n",
        "    \"fbs\": [1],\n",
        "    \"restecg\": [0],\n",
        "    \"thalach\": [150],\n",
        "    \"exang\": [0],\n",
        "    \"oldpeak\": [2.3],\n",
        "    \"slope\": [0],\n",
        "    \"ca\": [0],\n",
        "    \"thal\": [1]\n",
        "}\n",
        "\n",
        "# Convert evidence to DataFrame\n",
        "evidence_df = pd.DataFrame(evidence)\n",
        "\n",
        "# Print the nodes of the Bayesian network model\n",
        "print(\"Nodes of the Bayesian network model:\")\n",
        "print(model.nodes())\n",
        "\n",
        "# Check for variables present in evidence but not in the model\n",
        "missing_variables = set(evidence_df.columns) - set(model.nodes())\n",
        "if missing_variables:\n",
        "    raise ValueError(\"Data has variables which are not in the model\")\n",
        "\n",
        "# Perform inference to diagnose heart disease\n",
        "diagnosis = model.predict_probability(evidence_df)\n",
        "print(diagnosis)\n"
      ],
      "metadata": {
        "id": "nlYQUNYZacWl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}